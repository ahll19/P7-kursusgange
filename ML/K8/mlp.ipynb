{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data import\n",
    "path = \"mnist_all/\"\n",
    "train = []\n",
    "test = []\n",
    "for i in range(10):\n",
    "    train.append(np.loadtxt(path+f\"train{i}.txt\"))\n",
    "    test.append(np.loadtxt(path+f\"test{i}.txt\"))\n",
    "\n",
    "y_train = []\n",
    "y_test = []\n",
    "for i in range(len(train)):\n",
    "    yi_train = np.zeros(len(train[i]), dtype=int)+i\n",
    "    y_train.append(yi_train)\n",
    "\n",
    "    yi_test = np.zeros(len(test[i]), dtype=int)+i\n",
    "    y_test.append(yi_test)\n",
    "\n",
    "train_stacked = np.vstack(train)\n",
    "y_train = np.hstack(y_train)\n",
    "\n",
    "test_stacked = np.vstack(test)\n",
    "y_test = np.hstack(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing data dim\n",
    "dim = 2\n",
    "\n",
    "pca_dim = PCA(n_components=dim)\n",
    "\n",
    "train_pca = pca_dim.fit_transform(train_stacked)\n",
    "test_pca = pca_dim.fit_transform(test_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch\n",
    "class NumbersDataset(Dataset):\n",
    "    def __init__(self, samples, labels):\n",
    "        self.samples = torch.from_numpy(samples).to(torch.float32)\n",
    "        self.labels = torch.from_numpy(labels).to(torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numbersdataset to convert to torch\n",
    "batch_size = 100\n",
    "hidden_size = 100\n",
    "num_classes = 10 # 10 image classes\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2\n",
    "\n",
    "train_data = NumbersDataset(train_pca, y_train)\n",
    "test_data = NumbersDataset(test_pca, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 50, step 100 / 600, loss = 6.4458\n",
      "epoch: 1 / 50, step 200 / 600, loss = 2.4653\n",
      "epoch: 1 / 50, step 300 / 600, loss = 2.0812\n",
      "epoch: 1 / 50, step 400 / 600, loss = 3.1145\n",
      "epoch: 1 / 50, step 500 / 600, loss = 2.5993\n",
      "epoch: 1 / 50, step 600 / 600, loss = 2.3721\n",
      "epoch: 2 / 50, step 100 / 600, loss = 3.0284\n",
      "epoch: 2 / 50, step 200 / 600, loss = 2.5636\n",
      "epoch: 2 / 50, step 300 / 600, loss = 2.3103\n",
      "epoch: 2 / 50, step 400 / 600, loss = 1.9345\n",
      "epoch: 2 / 50, step 500 / 600, loss = 2.6874\n",
      "epoch: 2 / 50, step 600 / 600, loss = 2.0207\n",
      "epoch: 3 / 50, step 100 / 600, loss = 2.1289\n",
      "epoch: 3 / 50, step 200 / 600, loss = 2.1093\n",
      "epoch: 3 / 50, step 300 / 600, loss = 2.1248\n",
      "epoch: 3 / 50, step 400 / 600, loss = 2.0304\n",
      "epoch: 3 / 50, step 500 / 600, loss = 3.2490\n",
      "epoch: 3 / 50, step 600 / 600, loss = 2.2196\n",
      "epoch: 4 / 50, step 100 / 600, loss = 2.4366\n",
      "epoch: 4 / 50, step 200 / 600, loss = 2.3403\n",
      "epoch: 4 / 50, step 300 / 600, loss = 3.0525\n",
      "epoch: 4 / 50, step 400 / 600, loss = 2.3525\n",
      "epoch: 4 / 50, step 500 / 600, loss = 2.6037\n",
      "epoch: 4 / 50, step 600 / 600, loss = 1.8026\n",
      "epoch: 5 / 50, step 100 / 600, loss = 2.6410\n",
      "epoch: 5 / 50, step 200 / 600, loss = 2.3035\n",
      "epoch: 5 / 50, step 300 / 600, loss = 2.2863\n",
      "epoch: 5 / 50, step 400 / 600, loss = 1.9696\n",
      "epoch: 5 / 50, step 500 / 600, loss = 2.1090\n",
      "epoch: 5 / 50, step 600 / 600, loss = 2.2630\n",
      "epoch: 6 / 50, step 100 / 600, loss = 2.0125\n",
      "epoch: 6 / 50, step 200 / 600, loss = 2.5681\n",
      "epoch: 6 / 50, step 300 / 600, loss = 2.4583\n",
      "epoch: 6 / 50, step 400 / 600, loss = 2.3410\n",
      "epoch: 6 / 50, step 500 / 600, loss = 2.3302\n",
      "epoch: 6 / 50, step 600 / 600, loss = 2.6474\n",
      "epoch: 7 / 50, step 100 / 600, loss = 2.1707\n",
      "epoch: 7 / 50, step 200 / 600, loss = 1.8616\n",
      "epoch: 7 / 50, step 300 / 600, loss = 2.4776\n",
      "epoch: 7 / 50, step 400 / 600, loss = 2.0736\n",
      "epoch: 7 / 50, step 500 / 600, loss = 2.6574\n",
      "epoch: 7 / 50, step 600 / 600, loss = 2.4733\n",
      "epoch: 8 / 50, step 100 / 600, loss = 2.3964\n",
      "epoch: 8 / 50, step 200 / 600, loss = 1.7450\n",
      "epoch: 8 / 50, step 300 / 600, loss = 2.4967\n",
      "epoch: 8 / 50, step 400 / 600, loss = 1.6453\n",
      "epoch: 8 / 50, step 500 / 600, loss = 2.0420\n",
      "epoch: 8 / 50, step 600 / 600, loss = 2.4074\n",
      "epoch: 9 / 50, step 100 / 600, loss = 2.6216\n",
      "epoch: 9 / 50, step 200 / 600, loss = 2.1111\n",
      "epoch: 9 / 50, step 300 / 600, loss = 2.3167\n",
      "epoch: 9 / 50, step 400 / 600, loss = 2.3539\n",
      "epoch: 9 / 50, step 500 / 600, loss = 2.4877\n",
      "epoch: 9 / 50, step 600 / 600, loss = 2.4558\n",
      "epoch: 10 / 50, step 100 / 600, loss = 2.9214\n",
      "epoch: 10 / 50, step 200 / 600, loss = 2.0293\n",
      "epoch: 10 / 50, step 300 / 600, loss = 2.7446\n",
      "epoch: 10 / 50, step 400 / 600, loss = 1.8897\n",
      "epoch: 10 / 50, step 500 / 600, loss = 2.5471\n",
      "epoch: 10 / 50, step 600 / 600, loss = 2.7170\n",
      "epoch: 11 / 50, step 100 / 600, loss = 2.4112\n",
      "epoch: 11 / 50, step 200 / 600, loss = 2.0418\n",
      "epoch: 11 / 50, step 300 / 600, loss = 1.7966\n",
      "epoch: 11 / 50, step 400 / 600, loss = 2.4559\n",
      "epoch: 11 / 50, step 500 / 600, loss = 2.2446\n",
      "epoch: 11 / 50, step 600 / 600, loss = 2.0510\n",
      "epoch: 12 / 50, step 100 / 600, loss = 1.9517\n",
      "epoch: 12 / 50, step 200 / 600, loss = 2.1873\n",
      "epoch: 12 / 50, step 300 / 600, loss = 2.1562\n",
      "epoch: 12 / 50, step 400 / 600, loss = 3.6762\n",
      "epoch: 12 / 50, step 500 / 600, loss = 2.8090\n",
      "epoch: 12 / 50, step 600 / 600, loss = 2.3752\n",
      "epoch: 13 / 50, step 100 / 600, loss = 2.6844\n",
      "epoch: 13 / 50, step 200 / 600, loss = 3.3507\n",
      "epoch: 13 / 50, step 300 / 600, loss = 1.6911\n",
      "epoch: 13 / 50, step 400 / 600, loss = 1.5776\n",
      "epoch: 13 / 50, step 500 / 600, loss = 2.0147\n",
      "epoch: 13 / 50, step 600 / 600, loss = 2.2876\n",
      "epoch: 14 / 50, step 100 / 600, loss = 2.4550\n",
      "epoch: 14 / 50, step 200 / 600, loss = 2.1014\n",
      "epoch: 14 / 50, step 300 / 600, loss = 2.1293\n",
      "epoch: 14 / 50, step 400 / 600, loss = 3.1670\n",
      "epoch: 14 / 50, step 500 / 600, loss = 3.3969\n",
      "epoch: 14 / 50, step 600 / 600, loss = 2.2176\n",
      "epoch: 15 / 50, step 100 / 600, loss = 2.1797\n",
      "epoch: 15 / 50, step 200 / 600, loss = 2.8685\n",
      "epoch: 15 / 50, step 300 / 600, loss = 2.2223\n",
      "epoch: 15 / 50, step 400 / 600, loss = 2.7189\n",
      "epoch: 15 / 50, step 500 / 600, loss = 2.7799\n",
      "epoch: 15 / 50, step 600 / 600, loss = 2.6468\n",
      "epoch: 16 / 50, step 100 / 600, loss = 2.6812\n",
      "epoch: 16 / 50, step 200 / 600, loss = 2.1435\n",
      "epoch: 16 / 50, step 300 / 600, loss = 2.1875\n",
      "epoch: 16 / 50, step 400 / 600, loss = 1.8750\n",
      "epoch: 16 / 50, step 500 / 600, loss = 2.0450\n",
      "epoch: 16 / 50, step 600 / 600, loss = 2.2181\n",
      "epoch: 17 / 50, step 100 / 600, loss = 2.0889\n",
      "epoch: 17 / 50, step 200 / 600, loss = 1.7770\n",
      "epoch: 17 / 50, step 300 / 600, loss = 2.0157\n",
      "epoch: 17 / 50, step 400 / 600, loss = 1.9477\n",
      "epoch: 17 / 50, step 500 / 600, loss = 2.1492\n",
      "epoch: 17 / 50, step 600 / 600, loss = 2.0401\n",
      "epoch: 18 / 50, step 100 / 600, loss = 2.3095\n",
      "epoch: 18 / 50, step 200 / 600, loss = 1.8090\n",
      "epoch: 18 / 50, step 300 / 600, loss = 1.7693\n",
      "epoch: 18 / 50, step 400 / 600, loss = 2.2214\n",
      "epoch: 18 / 50, step 500 / 600, loss = 1.8411\n",
      "epoch: 18 / 50, step 600 / 600, loss = 1.9246\n",
      "epoch: 19 / 50, step 100 / 600, loss = 2.1495\n",
      "epoch: 19 / 50, step 200 / 600, loss = 1.8862\n",
      "epoch: 19 / 50, step 300 / 600, loss = 1.8516\n",
      "epoch: 19 / 50, step 400 / 600, loss = 1.9918\n",
      "epoch: 19 / 50, step 500 / 600, loss = 1.7540\n",
      "epoch: 19 / 50, step 600 / 600, loss = 1.5644\n",
      "epoch: 20 / 50, step 100 / 600, loss = 1.8587\n",
      "epoch: 20 / 50, step 200 / 600, loss = 1.9102\n",
      "epoch: 20 / 50, step 300 / 600, loss = 1.8555\n",
      "epoch: 20 / 50, step 400 / 600, loss = 2.6272\n",
      "epoch: 20 / 50, step 500 / 600, loss = 2.3035\n",
      "epoch: 20 / 50, step 600 / 600, loss = 1.6200\n",
      "epoch: 21 / 50, step 100 / 600, loss = 2.3275\n",
      "epoch: 21 / 50, step 200 / 600, loss = 3.0626\n",
      "epoch: 21 / 50, step 300 / 600, loss = 2.7856\n",
      "epoch: 21 / 50, step 400 / 600, loss = 1.9087\n",
      "epoch: 21 / 50, step 500 / 600, loss = 1.5054\n",
      "epoch: 21 / 50, step 600 / 600, loss = 2.0092\n",
      "epoch: 22 / 50, step 100 / 600, loss = 1.8637\n",
      "epoch: 22 / 50, step 200 / 600, loss = 1.9968\n",
      "epoch: 22 / 50, step 300 / 600, loss = 1.4716\n",
      "epoch: 22 / 50, step 400 / 600, loss = 1.8771\n",
      "epoch: 22 / 50, step 500 / 600, loss = 1.9302\n",
      "epoch: 22 / 50, step 600 / 600, loss = 2.1237\n",
      "epoch: 23 / 50, step 100 / 600, loss = 2.0132\n",
      "epoch: 23 / 50, step 200 / 600, loss = 1.7046\n",
      "epoch: 23 / 50, step 300 / 600, loss = 1.9574\n",
      "epoch: 23 / 50, step 400 / 600, loss = 1.6010\n",
      "epoch: 23 / 50, step 500 / 600, loss = 2.3660\n",
      "epoch: 23 / 50, step 600 / 600, loss = 2.0905\n",
      "epoch: 24 / 50, step 100 / 600, loss = 1.6385\n",
      "epoch: 24 / 50, step 200 / 600, loss = 2.9342\n",
      "epoch: 24 / 50, step 300 / 600, loss = 2.1350\n",
      "epoch: 24 / 50, step 400 / 600, loss = 2.2596\n",
      "epoch: 24 / 50, step 500 / 600, loss = 2.5066\n",
      "epoch: 24 / 50, step 600 / 600, loss = 2.0261\n",
      "epoch: 25 / 50, step 100 / 600, loss = 1.9783\n",
      "epoch: 25 / 50, step 200 / 600, loss = 1.8609\n",
      "epoch: 25 / 50, step 300 / 600, loss = 2.1723\n",
      "epoch: 25 / 50, step 400 / 600, loss = 2.2019\n",
      "epoch: 25 / 50, step 500 / 600, loss = 2.6835\n",
      "epoch: 25 / 50, step 600 / 600, loss = 2.3349\n",
      "epoch: 26 / 50, step 100 / 600, loss = 2.0323\n",
      "epoch: 26 / 50, step 200 / 600, loss = 2.0190\n",
      "epoch: 26 / 50, step 300 / 600, loss = 2.0664\n",
      "epoch: 26 / 50, step 400 / 600, loss = 1.8191\n",
      "epoch: 26 / 50, step 500 / 600, loss = 2.1102\n",
      "epoch: 26 / 50, step 600 / 600, loss = 1.9313\n",
      "epoch: 27 / 50, step 100 / 600, loss = 2.1127\n",
      "epoch: 27 / 50, step 200 / 600, loss = 1.8951\n",
      "epoch: 27 / 50, step 300 / 600, loss = 1.8444\n",
      "epoch: 27 / 50, step 400 / 600, loss = 1.9404\n",
      "epoch: 27 / 50, step 500 / 600, loss = 1.6381\n",
      "epoch: 27 / 50, step 600 / 600, loss = 1.9791\n",
      "epoch: 28 / 50, step 100 / 600, loss = 2.3031\n",
      "epoch: 28 / 50, step 200 / 600, loss = 2.0201\n",
      "epoch: 28 / 50, step 300 / 600, loss = 2.0204\n",
      "epoch: 28 / 50, step 400 / 600, loss = 1.7993\n",
      "epoch: 28 / 50, step 500 / 600, loss = 2.2673\n",
      "epoch: 28 / 50, step 600 / 600, loss = 2.6742\n",
      "epoch: 29 / 50, step 100 / 600, loss = 1.7952\n",
      "epoch: 29 / 50, step 200 / 600, loss = 2.4568\n",
      "epoch: 29 / 50, step 300 / 600, loss = 1.8943\n",
      "epoch: 29 / 50, step 400 / 600, loss = 2.0095\n",
      "epoch: 29 / 50, step 500 / 600, loss = 2.5080\n",
      "epoch: 29 / 50, step 600 / 600, loss = 1.3903\n",
      "epoch: 30 / 50, step 100 / 600, loss = 2.0406\n",
      "epoch: 30 / 50, step 200 / 600, loss = 1.6526\n",
      "epoch: 30 / 50, step 300 / 600, loss = 2.0201\n",
      "epoch: 30 / 50, step 400 / 600, loss = 1.8715\n",
      "epoch: 30 / 50, step 500 / 600, loss = 1.9155\n",
      "epoch: 30 / 50, step 600 / 600, loss = 1.6660\n",
      "epoch: 31 / 50, step 100 / 600, loss = 2.3427\n",
      "epoch: 31 / 50, step 200 / 600, loss = 2.7153\n",
      "epoch: 31 / 50, step 300 / 600, loss = 2.1194\n",
      "epoch: 31 / 50, step 400 / 600, loss = 1.8913\n",
      "epoch: 31 / 50, step 500 / 600, loss = 2.1198\n",
      "epoch: 31 / 50, step 600 / 600, loss = 1.9389\n",
      "epoch: 32 / 50, step 100 / 600, loss = 2.3715\n",
      "epoch: 32 / 50, step 200 / 600, loss = 2.3387\n",
      "epoch: 32 / 50, step 300 / 600, loss = 2.0743\n",
      "epoch: 32 / 50, step 400 / 600, loss = 2.0619\n",
      "epoch: 32 / 50, step 500 / 600, loss = 1.7483\n",
      "epoch: 32 / 50, step 600 / 600, loss = 2.6411\n",
      "epoch: 33 / 50, step 100 / 600, loss = 1.6403\n",
      "epoch: 33 / 50, step 200 / 600, loss = 2.0809\n",
      "epoch: 33 / 50, step 300 / 600, loss = 1.6158\n",
      "epoch: 33 / 50, step 400 / 600, loss = 1.6916\n",
      "epoch: 33 / 50, step 500 / 600, loss = 1.9412\n",
      "epoch: 33 / 50, step 600 / 600, loss = 1.7275\n",
      "epoch: 34 / 50, step 100 / 600, loss = 2.1620\n",
      "epoch: 34 / 50, step 200 / 600, loss = 2.0752\n",
      "epoch: 34 / 50, step 300 / 600, loss = 1.7025\n",
      "epoch: 34 / 50, step 400 / 600, loss = 1.9650\n",
      "epoch: 34 / 50, step 500 / 600, loss = 2.2310\n",
      "epoch: 34 / 50, step 600 / 600, loss = 2.0770\n",
      "epoch: 35 / 50, step 100 / 600, loss = 2.1192\n",
      "epoch: 35 / 50, step 200 / 600, loss = 1.6432\n",
      "epoch: 35 / 50, step 300 / 600, loss = 2.0347\n",
      "epoch: 35 / 50, step 400 / 600, loss = 2.0889\n",
      "epoch: 35 / 50, step 500 / 600, loss = 2.2526\n",
      "epoch: 35 / 50, step 600 / 600, loss = 1.9343\n",
      "epoch: 36 / 50, step 100 / 600, loss = 1.9823\n",
      "epoch: 36 / 50, step 200 / 600, loss = 2.2897\n",
      "epoch: 36 / 50, step 300 / 600, loss = 2.5075\n",
      "epoch: 36 / 50, step 400 / 600, loss = 2.0432\n",
      "epoch: 36 / 50, step 500 / 600, loss = 2.0221\n",
      "epoch: 36 / 50, step 600 / 600, loss = 1.9462\n",
      "epoch: 37 / 50, step 100 / 600, loss = 1.8080\n",
      "epoch: 37 / 50, step 200 / 600, loss = 1.6810\n",
      "epoch: 37 / 50, step 300 / 600, loss = 1.5097\n",
      "epoch: 37 / 50, step 400 / 600, loss = 2.2542\n",
      "epoch: 37 / 50, step 500 / 600, loss = 1.4463\n",
      "epoch: 37 / 50, step 600 / 600, loss = 2.4444\n",
      "epoch: 38 / 50, step 100 / 600, loss = 1.6663\n",
      "epoch: 38 / 50, step 200 / 600, loss = 2.0289\n",
      "epoch: 38 / 50, step 300 / 600, loss = 2.1211\n",
      "epoch: 38 / 50, step 400 / 600, loss = 2.2279\n",
      "epoch: 38 / 50, step 500 / 600, loss = 1.9445\n",
      "epoch: 38 / 50, step 600 / 600, loss = 1.6746\n",
      "epoch: 39 / 50, step 100 / 600, loss = 1.9672\n",
      "epoch: 39 / 50, step 200 / 600, loss = 1.7467\n",
      "epoch: 39 / 50, step 300 / 600, loss = 1.5554\n",
      "epoch: 39 / 50, step 400 / 600, loss = 1.6349\n",
      "epoch: 39 / 50, step 500 / 600, loss = 1.7490\n",
      "epoch: 39 / 50, step 600 / 600, loss = 1.7627\n",
      "epoch: 40 / 50, step 100 / 600, loss = 1.9103\n",
      "epoch: 40 / 50, step 200 / 600, loss = 1.9175\n",
      "epoch: 40 / 50, step 300 / 600, loss = 1.9264\n",
      "epoch: 40 / 50, step 400 / 600, loss = 1.6200\n",
      "epoch: 40 / 50, step 500 / 600, loss = 1.9963\n",
      "epoch: 40 / 50, step 600 / 600, loss = 1.7460\n",
      "epoch: 41 / 50, step 100 / 600, loss = 1.9262\n",
      "epoch: 41 / 50, step 200 / 600, loss = 1.5679\n",
      "epoch: 41 / 50, step 300 / 600, loss = 1.5814\n",
      "epoch: 41 / 50, step 400 / 600, loss = 1.7885\n",
      "epoch: 41 / 50, step 500 / 600, loss = 1.9312\n",
      "epoch: 41 / 50, step 600 / 600, loss = 1.3770\n",
      "epoch: 42 / 50, step 100 / 600, loss = 2.5403\n",
      "epoch: 42 / 50, step 200 / 600, loss = 1.7014\n",
      "epoch: 42 / 50, step 300 / 600, loss = 2.3295\n",
      "epoch: 42 / 50, step 400 / 600, loss = 2.0241\n",
      "epoch: 42 / 50, step 500 / 600, loss = 1.8535\n",
      "epoch: 42 / 50, step 600 / 600, loss = 2.9674\n",
      "epoch: 43 / 50, step 100 / 600, loss = 1.8716\n",
      "epoch: 43 / 50, step 200 / 600, loss = 1.7692\n",
      "epoch: 43 / 50, step 300 / 600, loss = 1.7774\n",
      "epoch: 43 / 50, step 400 / 600, loss = 1.7898\n",
      "epoch: 43 / 50, step 500 / 600, loss = 2.2252\n",
      "epoch: 43 / 50, step 600 / 600, loss = 1.7222\n",
      "epoch: 44 / 50, step 100 / 600, loss = 1.9423\n",
      "epoch: 44 / 50, step 200 / 600, loss = 1.8704\n",
      "epoch: 44 / 50, step 300 / 600, loss = 1.7542\n",
      "epoch: 44 / 50, step 400 / 600, loss = 1.6853\n",
      "epoch: 44 / 50, step 500 / 600, loss = 1.9921\n",
      "epoch: 44 / 50, step 600 / 600, loss = 1.3820\n",
      "epoch: 45 / 50, step 100 / 600, loss = 1.4980\n",
      "epoch: 45 / 50, step 200 / 600, loss = 1.5540\n",
      "epoch: 45 / 50, step 300 / 600, loss = 1.7518\n",
      "epoch: 45 / 50, step 400 / 600, loss = 1.8756\n",
      "epoch: 45 / 50, step 500 / 600, loss = 1.5799\n",
      "epoch: 45 / 50, step 600 / 600, loss = 1.5136\n",
      "epoch: 46 / 50, step 100 / 600, loss = 1.8276\n",
      "epoch: 46 / 50, step 200 / 600, loss = 1.7818\n",
      "epoch: 46 / 50, step 300 / 600, loss = 1.6946\n",
      "epoch: 46 / 50, step 400 / 600, loss = 1.5769\n",
      "epoch: 46 / 50, step 500 / 600, loss = 1.7212\n",
      "epoch: 46 / 50, step 600 / 600, loss = 1.7944\n",
      "epoch: 47 / 50, step 100 / 600, loss = 1.8124\n",
      "epoch: 47 / 50, step 200 / 600, loss = 1.9717\n",
      "epoch: 47 / 50, step 300 / 600, loss = 1.4791\n",
      "epoch: 47 / 50, step 400 / 600, loss = 2.1953\n",
      "epoch: 47 / 50, step 500 / 600, loss = 1.7017\n",
      "epoch: 47 / 50, step 600 / 600, loss = 2.3834\n",
      "epoch: 48 / 50, step 100 / 600, loss = 2.0245\n",
      "epoch: 48 / 50, step 200 / 600, loss = 1.7013\n",
      "epoch: 48 / 50, step 300 / 600, loss = 1.9929\n",
      "epoch: 48 / 50, step 400 / 600, loss = 1.9119\n",
      "epoch: 48 / 50, step 500 / 600, loss = 2.7772\n",
      "epoch: 48 / 50, step 600 / 600, loss = 1.7720\n",
      "epoch: 49 / 50, step 100 / 600, loss = 1.7462\n",
      "epoch: 49 / 50, step 200 / 600, loss = 1.8749\n",
      "epoch: 49 / 50, step 300 / 600, loss = 1.7485\n",
      "epoch: 49 / 50, step 400 / 600, loss = 1.5223\n",
      "epoch: 49 / 50, step 500 / 600, loss = 2.1863\n",
      "epoch: 49 / 50, step 600 / 600, loss = 1.8076\n",
      "epoch: 50 / 50, step 100 / 600, loss = 1.8691\n",
      "epoch: 50 / 50, step 200 / 600, loss = 1.6918\n",
      "epoch: 50 / 50, step 300 / 600, loss = 1.7230\n",
      "epoch: 50 / 50, step 400 / 600, loss = 2.1001\n",
      "epoch: 50 / 50, step 500 / 600, loss = 1.5269\n",
      "epoch: 50 / 50, step 600 / 600, loss = 1.9113\n",
      "accuracy = 12.86\n"
     ]
    }
   ],
   "source": [
    "# Create network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out) # NOT USE SOFTMAX SINCE WE USE nn.CrossEntropyLoss (it is implemented in there)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(dim, hidden_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # image shape 100, 1, 28, 28 - hence we resize to 100,784\n",
    "        images = images.reshape(-1, dim)\n",
    "        labels = labels\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        #print(outputs, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backwards\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"epoch: {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}\")\n",
    "\n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, dim)\n",
    "        labels = labels\n",
    "        outputs = model(images) # trained model\n",
    "\n",
    "        _, pred = torch.max(outputs, 1) #value, index\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (pred == labels).sum().item()\n",
    "\n",
    "    acc = 100.0*n_correct/n_samples\n",
    "    print(f\"accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('uni_python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a1dc1df412c4b1b7f123b1b4ec1059ad232d9475d2964d51cd2f39dfe4e8cc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
